%\colin{TODO: emphasize blackbox vs whitebox minimization?}
%\colin{TODO: Admit up front that, most bugs, even in distributed systems, can
%be minimized with traditional delta debugging (e.g. unexpected configurations,
%unexpected messages, etc.). However, the bugs that are the most difficult are
%those that involve concurrency \& asynchrony.}

Even simple code can contain bugs (e.g., crashes due to unexpected input). But the developers
of distributed systems face
additional challenges, such as concurrency, asynchrony, and partial failure, which require them to
consider all possible ways that non-determinism might manifest itself. Since
the number of event orderings %(e.g.,message deliveries, failure notifications)
a distributed system may encounter grows exponentially with the number of events, bugs are commonplace.

% TODO(cs): simpler version of the above paragraph:
% Developers
% of distributed systems need to consider many scenarios in which the components of the system must operate,
% due to concurrency, asynchrony, and partial failures. Since analyzing these scenarios is so complex,
% it is common for distributed systems to have hard-to find bugs.

% Developers of distributed systems face %notoriously
% difficult challenges, such
% as concurrency, asynchrony, and
% partial failure. These challenges, in {\em addition} to those arising from normal software development, invariably lead to software bugs.
% 
% Bugs that are specific to distributed systems (as opposed to bugs normally encountered in sequential code, e.g. crashes due to unexpected user input) arise because
% it is difficult for developers to
% consider all the possible ways that non-determinism can manifest itself.
% The number of event orderings (e.g. message deliveries, failure notifications, etc.)
% a distributed system may encounter scales factorially with the cluster size and the execution length.
% % TODO(cs): swap order of "event-orderings" and "non-determinism"?

Software developers discover bugs in several ways.
Most commonly, they find them through unit and integration tests. These tests are ubiquitous, but they are limited to cases that developers
anticipate themselves. To uncover unanticipated cases, semi-automated testing techniques such as fuzzing (where
sequences of message deliveries, failures, etc. are injected into the system) are effective.
Finally, despite pre-release testing, bugs may turn up once the code is deployed in production.
% TODO(cs): provide citations on bugs found in production, or bugs found by fuzzing?

The last two means of bug discovery present a significant challenge to
developers: the system can run for
long periods before problems manifest themselves. The resulting executions
can contain a large number of events, most of which are not relevant to triggering the
bug. Understanding how a trace containing thousands of concurrent events lead
the system to an unsafe state requires significant expertise, time,\footnote{Developers spend a significant portion of their time
debugging (49\% of their time according to one
study~\cite{LaToza:2006:MMM:1134285.1134355}), especially when the bugs
involve concurrency (70\% of reported concurrency bugs
in~\cite{msoft_concurrency} took days to months to fix).}
and luck.

% Mention somewhere that bugs in distributed systems are important to fix?

Faulty execution traces can be made %substantially
easier to understand if they are first
{\em minimized}, so that only events that are relevant to triggering the bug remain.
In fact, developers often start troubleshooting by manually performing this minimization.
Since developer time is typically much more costly than machine time,
automated minimization tools for {\em sequential}
test
cases~\cite{claessen2000quickcheck,Zeller:2002:SIF:506201.506206,yang2011finding}
have already proven themselves valuable,
and are routinely applied to bug reports for software projects such as Firefox~\cite{firefox_reduction}, LLVM~\cite{bugpoint}, and GCC~\cite{gcc_reduction}.
%\george{any cites from distributed systems?}

In this paper we address the problem of automatically minimizing executions of distributed systems. We
focus on executions generated by fuzz testing, but we also
illustrate how one might minimize production traces.

%Other than our prior work, the closest approaches we know of work by
% symbolically analyzing the program, which suffer from a different set of
% limitations.

Distributed executions have two distinguishing features. Most importantly, input events
(e.g., failures)
are {\em interleaved} with internal events (e.g., intra-process
message deliveries) of concurrent processes. Minimization algorithms must therefore consider both which
input events and which (of the exponentially many)
event schedules are likely to still trigger the bug. Our main contribution
(discussed in section~\ref{dsec:approach}) is a set of techniques for searching
through the space of event schedules in a timely manner; these techniques are inspired
by our understanding of how practical systems behave.

Distributed systems also frequently exhibit non-determinism (e.g., since they
make extensive use of timers to detect failures), complicating replay. We address this
challenge (as we discuss in
section~\ref{dsec:implementation}) by
instrumenting the Akka actor system framework~\cite{akka} to gain nearly perfect control over when
events occur.

With the exception of our prior work~\cite{sts2014}, we are unaware of any other
tool that solves this problem without needing to analyze the code.
Our prior work targeted a specific distributed system (SDN controllers), and focused
on minimizing input events given limited control over the execution~\cite{sts2014}.
Here we target a broader range of systems, define the
general problem of execution minimization, exercise significantly greater
control, and systematically explore the state space. We also articulate new minimization
strategies that quickly reduce input events,
internal events, and message contents.

%In our evaluation, we provide
% empirical comparisons of old and new scheduling strategies.

% TODO(cs): what can DEMi not do?

Our tool, \system~(\sys), is implemented in {\footnotesize $\sim$}14,000
lines of Scala. We have applied \sys~to akka-raft~\cite{akka-raft}, an open
source Raft consensus implementation, and Apache Spark~\cite{zaharia2012resilient}, a widely used data analytics framework.
Across 10 known and discovered bugs, \sys~produces executions that are within
a factor of 1X to 4.6X (1.6X median) the size of the smallest possible
bug-triggering execution,
and between 1X and 16X (4X median) smaller than the
executions produced by the previous state-of-the-art blackbox technique~\cite{sts2014}.
The results we find for these two very different systems leave us optimistic that these
techniques, along with adequate visibility into events (either through a
framework like Akka, or through
custom monitoring), can be applied successfully to a wider range of systems.

%\colin{"Integrated programming environment"}
% \colin{articulate tradeoff between overly-specific vs overly-general
% minimization specifications. Have this as part of a discussion section?}

% Contributions:
%   https://docs.google.com/document/d/1Y5WBlv6iul-HP74DM37gTfx1tzUtfZTowqD4Db11US4/edit
% Limitations of the SIGCOMM paper:
%
% limited control over the execution
%   execution is not linearizable -> depend on wall-clock time to infer whether expected events are or are not going to show up during replay
%   limited to no control over sources of non-determinism
% no clean formulation
%   no intuition for why the heuristics work
% narrow system target (SDN controllers)
%
% Contributions of the NSDI paper:
%
% broader system target
%   - Spark, Raft, JavaScript, reliable broadcast, {SDN?, DHT?, distributed database?}
%   - multiple bug types for each
% more control over the execution
%   - actor model gives us atomicity (linearizability): we know exactly when the actor has fully processed the last message we delivered to it -> no need to wait on wall-clock to see whether it’s going to send some expected message
%   - narrower API also helps us mitigate non-determinism somewhat
% clean problem formulation
%   - lay out all degrees of freedom: removal of external events, network schedule, external message contents, cluster size, etc.
%   - articulate what would be required to arrive at the ideal output (build an intuition for possible heuristics) & explain why that’s intractable. Instead: we have a fixed computational budget, and we want to maximize minimization within the budget.
%   - reordering of messages (edit distance)
%   - minimization of internal messages, in addition to external messages
%   - shrinking of message contents, cluster size
%   - module minimization?
% empirical data on effectiveness of heuristics
%   - compare minimality, runtime complexity for each of the heuristics. Specifically show how much each heuristic buys beyond the SIGCOMM heuristics.
%   - for a sampling of bugs, also compare against ground truth: either (i) a case where know by inspection exactly what the MCS should be, or (ii) a case where we are able to run DPOR to completion.
% conjectures (claims?) on why heuristics are effective
%   - explanation of the nature of QA tests, in terms of what code paths they tend to exercise
%   - computational models: constraints on how programs behave in practice. Examples: data-independence (fingerprinting), commutativity (DPOR), recency of state, bounded-edit-distance
%
%
% Delta from related work (also see: STS FAQ):
%
% traditional minimization (DDmin, QuickCheck’s shrinking)
%   not immediately applicable to systems with intermediate external events
% best-effort minimization (QuickCheck applied to concurrent systems, field failures) 
%   don’t systematically handle concurrency
% model checking minimization: MAX-Sat, interpolation (ConcBugAssist, DSPs)
%   many disadvantages of model checking. See STS FAQ.
% deterministic replay log minimization (schedule minimization, program analysis)
%   don’t allow divergence during replay! i.e. minimization specification is overly specific -> minimization results aren’t great
%   program flow analysis work is tied to a single language, + high perf overhead
% model inference, log summarization (synoptic, csight, invariant mining)
%   summarize the events that occurred, but don’t actually minimize the test case. Apply this after you minimize the test case with our techniques.
% program slicing, automated debugging (experimental, program analysis)
%   minimize program statements, but not the test case itself. Useful for debugging, but not troubleshooting. Apply this after you minimize the test case with our techniques.
%
% STS FAQ:
%
% why not analyze the program?
%   ties you to one language
%   parsers usually aren’t complete; will sometimes have to make assumptions that aren’t realistic
%   requires engineering effort to get working
%   high computational overhead of tracing
%   by solving a harder problem, we come up with more interesting solutions
%
% Is QA testing going to be around forever? Why not use newer more sophisticated testing tools?
%   As long as you have bugs in production, you will need minimization.
%
% Why is previous work (STS) unsatisfying?
%   we know there are some MCSes that are not minimal
%   no empirical comparison of heuristics vs. other heuristics
%   no intuition for why heuristics work, or how to come up with other heuristics
%
% Why is minimization needed?
%
% How do we deal with non-determinism?
%
% Why be loosey-goosey about which specific safety violation we trigger? (why not require exact same failing code path?)

% TODO(cs): what kinds of distributed systems are we targeting? Primarily
% control plane systems, which are designed to operate indefinitely.
% TODO(cs): in the introduction, illustrate a compelling example that shows
% why 1000s of events are a difficult starting point for debugging.
